"""Modal deployment for exploitative LLM poker bot training.

This script deploys the exploitative LLM training to Modal cloud platform,
allowing you to train against your GTO checkpoint at scale.
"""

import modal
import os

# Get the project root directory
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))

# Modal image with all dependencies
image = (
    modal.Image.debian_slim(python_version="3.10")
    .pip_install(
        "torch>=2.0.0",
        "numpy>=1.24.0",
        "tqdm>=4.65.0",
        "tinker-client>=0.1.0",
        "tinker-cookbook>=0.1.0",
    )
    .add_local_dir(
        os.path.join(project_root, "poker_game"),
        "/root/poker_game"
    )
    .add_local_dir(
        os.path.join(project_root, "models"),
        "/root/models"
    )
    .add_local_dir(
        os.path.join(project_root, "training"),
        "/root/training"
    )
    .add_local_dir(
        os.path.join(project_root, "llm_poker"),
        "/root/llm_poker"
    )
    .add_local_dir(
        os.path.join(project_root, "checkpoints"),
        "/root/checkpoints"
    )
)

# Volumes for checkpoints and logs
checkpoint_volume = modal.Volume.from_name(
    "poker-exploitative-llm-checkpoints",
    create_if_missing=True
)
gto_checkpoint_volume = modal.Volume.from_name(
    "poker-bot-checkpoints",  # Your existing GTO checkpoints
    create_if_missing=True
)

app = modal.App("poker-exploitative-llm-training")


@app.function(
    image=image,
    volumes={
        "/checkpoints": checkpoint_volume,
        "/gto_checkpoints": gto_checkpoint_volume,
    },
    gpu="T4",  # T4 is sufficient for inference (GTO opponent)
    timeout=36000,  # 10 hours
    secrets=[modal.Secret.from_name("tinker-api-key")],  # Add your Tinker API key as a Modal secret
)
def train_exploitative_llm(
    model_name: str = "Qwen/Qwen3-4B-Instruct-2507",
    gto_checkpoint_name: str = "checkpoint_1000.pt",  # Your trained GTO checkpoint
    num_batches: int = 100,
    episodes_per_batch: int = 16,
    learning_rate: float = 4e-5,
    bluff_bonus: float = 0.5,
    aggression_bonus: float = 0.1,
    fold_equity_bonus: float = 0.3,
    exploitative_sizing_bonus: float = 0.2,
):
    """Train exploitative LLM on Modal.

    This function runs on Modal with GPU support and trains the LLM
    to exploit your GTO checkpoint.
    """
    import sys
    sys.path.insert(0, "/root")

    from scripts.train_exploitative_llm import run_exploitative_rl

    # GTO checkpoint path in Modal volume
    gto_checkpoint_path = f"/gto_checkpoints/{gto_checkpoint_name}"

    # Log path in Modal volume
    log_path = "/checkpoints/exploitative_llm_logs"

    print(f"Starting exploitative LLM training vs GTO checkpoint: {gto_checkpoint_path}")
    print(f"Model: {model_name}")
    print(f"Batches: {num_batches}, Episodes/batch: {episodes_per_batch}")
    print(f"Reward bonuses: bluff={bluff_bonus}, aggression={aggression_bonus}, "
          f"fold_equity={fold_equity_bonus}, sizing={exploitative_sizing_bonus}")

    run_exploitative_rl(
        model_name=model_name,
        log_path=log_path,
        gto_checkpoint_path=gto_checkpoint_path,
        num_batches=num_batches,
        episodes_per_batch=episodes_per_batch,
        learning_rate=learning_rate,
        max_tokens=32,
        lora_rank=16,
        base_url=None,  # Use default Tinker API
        bluff_bonus=bluff_bonus,
        aggression_bonus=aggression_bonus,
        fold_equity_bonus=fold_equity_bonus,
        exploitative_sizing_bonus=exploitative_sizing_bonus,
    )

    # Commit checkpoint volume
    checkpoint_volume.commit()

    print("Exploitative LLM training completed!")
    print(f"Checkpoints saved to Modal volume: poker-exploitative-llm-checkpoints")

    return {
        "status": "completed",
        "log_path": log_path,
        "num_batches": num_batches,
    }


@app.local_entrypoint()
def main(
    model_name: str = "Qwen/Qwen3-4B-Instruct-2507",
    gto_checkpoint: str = "checkpoint_1000.pt",
    num_batches: int = 100,
    episodes_per_batch: int = 16,
):
    """Local entrypoint to launch training on Modal."""
    print("Launching exploitative LLM training on Modal...")

    result = train_exploitative_llm.remote(
        model_name=model_name,
        gto_checkpoint_name=gto_checkpoint,
        num_batches=num_batches,
        episodes_per_batch=episodes_per_batch,
    )

    print(f"Training result: {result}")
